{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab404cc1-674c-4835-9a23-6787001cb8ee",
   "metadata": {},
   "source": [
    "# Lang Chaineの使用法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa763f-4ee2-408c-a4f3-97cb2f0d3174",
   "metadata": {},
   "source": [
    "lang chaineを使用することで画一的にllmモデルを使用することができる。\n",
    "\n",
    "アプリケーションを作成する上で使用するllmモデルを変更できることは非常に有用である。そこでlangchainを使用して先のcreate-articleを作成し直す。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b4ebae-b8e9-460f-92aa-ae1b8c5d37a1",
   "metadata": {},
   "source": [
    "anaconda を使用しているため、conda install langchain -c conda-forgeを使用しライブラリをインストールした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41786b96-52d3-4b04-8a67-85b5042c9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c771e38b-3198-4c0c-a431-8bf28bf33ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.15'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3c05f-ef9b-4a6d-8ebf-f3e80f35e078",
   "metadata": {},
   "source": [
    "バージョンは0.3.15である。\n",
    "\n",
    "次にlangchain_openaiを使用するためにcondaを使用してインストールを行った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6572a1-205c-451a-9047-0b9a81339434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571c911-a51a-4798-83a8-372be6143fa6",
   "metadata": {},
   "source": [
    "次に、OPENAIのAPIを使用するためのキーを登録する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c06e404-7c13-4783-8441-d528332dff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02735051-8d91-4893-94a9-273b7627ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f8424-fbb7-4268-a6a0-72483d02cf06",
   "metadata": {},
   "source": [
    "ChatOpenAIを使用することで次のようにレスポンスを得ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d5a672c-b73a-4100-a90f-f82234071e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c56793a-1a97-4f53-99bc-37bdc07d2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "respond = llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9675ff79-f6f9-495c-973f-c607a7636c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(respond.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca7064-a303-46e3-b234-6415f95f406b",
   "metadata": {},
   "source": [
    "respondはインスタンスであり、複数の値が記録されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ac463d4-4804-488b-ba61-a3eacf0f7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f07fa245-6ee0-41cd-9b21-a66b67b228a7-0' usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(respond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8170e3d-d8ba-41bb-8eba-70cabbf342c2",
   "metadata": {},
   "source": [
    "使用したモデルの名前などが記録されている。\n",
    "\n",
    "これを使って先のcreate-articleと同様の実装を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b0e460b-86b8-472c-8e23-6ca8246a899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain を使った記事生成プログラム\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " 世界で一番の\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "旅行先…それは何でしょうか？\n",
      "\n",
      "こんにちは、皆さん！今日はちょっと趣向を変えて、旅好きな私が選ぶ「世界で一番の旅行先」についてお話したいと思います。夢見がちな話ね、だけどそれもまた楽しいじゃないですか。皆さんも何かしら理想とする旅行先があるはず。ですから、私が推す一番の旅行先があなたのリストに加わることを願います。\n",
      "\n",
      "さて、まずは想像力を働かせてください。目を閉じて、穏やかな海のイメージを思い浮かべてみてくれますか？青く透き通った海、白い砂浜、そしてゆっくりと時間が過ぎる非日常。手にはトロピカルなカクテルが握られ、陽気な音楽が聴こえてくる。それが私の選ぶ一番の旅行先、「カリブ海」です。\n",
      "\n",
      "私がカリブ海をおすすめする理由はいくつもあります。その一つが絶景で、これ以上ないほど美しいビーチと、透明度抜群の海。カリブ海に来れば、まるで自身が絵の中に入り込んだかのような感動を味わえます。一瞬で日常の雑念が飛んでいくのを感じることでしょう。\n",
      "\n",
      "次に、カリブ海の豊富なレジャーです。シュノーケリングやダイビングで色鮮やかな魚や珊瑚を見るのは格別な体験です。また、ヨットで海を語る、美しい海辺のレストランで食事を頂くなど、非日常的な生活が楽しめます。\n",
      "\n",
      "観光地としてもカリブ海は一級品で、歴史的な建造物や美術館、地元の市場など、観光できるスポットがたくさんあります。\n",
      "\n",
      "最後に、カリブ海の人々のホスピタリティを絶対に忘れてはいけません。親切でフレンドリーな現地の人々と交流することで、文化や伝統をより深く理解できます。実は以前私がカリブ海に行った際、道を尋ねた通行人が親切に道案内してくれたばかりか、地元のおすすめスポットも教えてくれたんです。その人々の優しさに感動したものです。\n",
      "\n",
      "皆さん、少しでも興味が湧いたら一度はカリブ海に足を運んでみてはいかがでしょうか? 体験するべきこと、観るべきものが満載で、間違いなくあなたの「世界で一番の旅行先」となるでしょう。\n",
      "\n",
      "それでは、皆さんの素晴らしい旅の始まりを心から祈っています！ ”旅は人を豊かにする” だなんて言いますし、豊かな体験と思い出を作るために、自分の”世界で一番の旅行先”を見つけに出かけてみてくださいね！\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " esc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "終了します。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import os\n",
    "\n",
    "\n",
    "def create_response(title):\n",
    "    # ChatGPTのインスタンス作成\n",
    "    chat = ChatOpenAI(model=\"gpt-4\", streaming=True)\n",
    "\n",
    "    # システムメッセージ\n",
    "    system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"適度にフランクな口調で記事を作成してください。読者への問いかけを一つだけ入れてください。\"\n",
    "            \"Markdownの形式で記述しないでください。身近な話題の場合は体験談も入れてください。\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # ユーザーからのメッセージ\n",
    "    human_message = HumanMessage(content=title)\n",
    "    \n",
    "    # ストリーミングでのレスポンス生成\n",
    "    response = chat([system_message, human_message])\n",
    "    \n",
    "    # 結果を表示\n",
    "    print(response.content, end=\"\", flush=True)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def main():\n",
    "    print(\"LangChain を使った記事生成プログラム\")\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "        create_response(title)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51e70644-cbb0-414d-b1e6-9cacb0eca798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain を使った記事生成プログラム\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " テスト\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "記事の生成中...\n",
      "\n",
      "タイトル：『「手に入れた！」iPhone12を使ってみてのリアルな感想』\n",
      "\n",
      "さぁ、iPhone好きのみんな、集まった？今日は、僕自身がついに手に入れたiPhone12についての感想を赤裸々にお伝えしようと思う。これがあなたのスマホ選びの参考になればと思うよ。ただし、僕はアップルの社員ではないから、内容は全然フィルターかけてない、ストレートな感想だから期待してくれよな！ \n",
      "\n",
      "最初に、持ち合わせてみてまず感じたのが、そのデザインの変化だ。視覚的な衝撃、直感的な感触。懐かしいでしょ？iPhone4、5の頃を思い出すよな、四角い形状。でもそのエッジはキレイに磨かれ、手にフィットする。その端正なデザイン、僕はずっとこの形状を待っていたんだ。\n",
      "\n",
      "さて、ここで一つ質問。君たちはiPhoneのカメラ機能、重視してる？ 僕はかなり重視していて、このiPhone12のカメラ性能がすごい。デュアルカメラシステムがまさにプロ仕様。光学ズーム表現力が上がったのと夜間撮影が大幅に進化。僕が北海道へ旅行に行った時の夜景、すっげえキレイに撮れたんだよ。\n",
      "\n",
      "そして何より、僕が一番気持ちよかったのが、その操作速度。もはや「サクサク」では表現しきれないほど。A14 Bionicチップのパフォーマンスは圧巻。ハイスペースゲームでも全然問題なし。それどころか、より快適にゲームが楽しめるのさ。\n",
      "\n",
      "ただ、ここで一つだけ注意点を挙げられるとすれば、それは価格だな。もちろん、それなりの価値はあると思う。でも、それなりの出費だからね。君にそれが許されるのか、それが問題になると思う。君が躊躇しないか、それもあなた次第だよ。\n",
      "\n",
      "でも、まぁ、それを差し引いても、僕はこのiPhone12に完全に満足している。あまりの満足度に今まで使ってたiPhone11を置いてきぼりにしちゃったね（笑）。\n",
      "\n",
      "さて、最後に。君たちに問いかけるよ：新しいiPhone12、君はどう感じる？ 結局のところ、スマホ選びは個々の好みだからね。でも、iPhone12の申し分のないパフォーマンスを考えると、この機会に新しいiPhoneにチャレンジしてみても良いと思うんじゃない？ ちょっとでも参考になれば僕も嬉しいんだけどな。\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " esc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "終了します。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def create_response(title):\n",
    "    \"\"\"\n",
    "    与えられたタイトルに基づいて、Llamaモデルでストリーミング対応のレスポンスを生成します。\n",
    "    \"\"\"\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\" or mode is None:\n",
    "        chat = ChatOpenAI(model=\"gpt-4\", streaming=True)\n",
    "    elif mode.lower() == \"google\":\n",
    "        chat = \n",
    "    # システムメッセージ\n",
    "    system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"適度にフランクな口調で記事を作成してください。読者への問いかけを一つだけ入れてください。\"\n",
    "            \"Markdownの形式で記述しないでください。身近な話題の場合は体験談も入れてください。\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ユーザーからの入力メッセージ\n",
    "    human_message = HumanMessage(content=title)\n",
    "\n",
    "    # ストリーミングのレスポンスを生成\n",
    "    print(\"\\n記事の生成中...\\n\")\n",
    "    for chunk in chat.stream([system_message, human_message]):\n",
    "        if chunk.content:\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    メインの対話ループ。\n",
    "    \"\"\"\n",
    "    print(\"LangChain を使った記事生成プログラム\")\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "        create_response(title)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04aadc30-f111-4bd2-bbaa-bd40d73bd8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai または google) \n",
      " google\n",
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " esc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "終了します。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "def GetEditor(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        wrighter = ChatOpenAI(model=\"gpt-4\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        wrighter = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0.7)\n",
    "    else:\n",
    "        wrighter = None\n",
    "    return wrighter\n",
    "\n",
    "def MakeMessage(title):\n",
    "    # システムメッセージ\n",
    "    system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "            \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "            \"フランクになりすぎないように気をつけてください。\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ユーザーからの入力メッセージ\n",
    "    human_message = HumanMessage(content=title)\n",
    "\n",
    "    return (system_message, human_message) \n",
    "\n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai または google) \\n\")\n",
    "        wrighter = GetEditor(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"openai または google を入力してください\")\n",
    "\n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "            \n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakeMessage(title)\n",
    "        \n",
    "        # ストリーミングのレスポンスを生成        \n",
    "        for chunk in wrighter.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad7e674b-6f56-4e9e-8deb-e9227598ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "wrighter = ChatOllama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70064865-ba12-4f7d-9f7c-8fb682b12052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " google\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode : google\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " test\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[56], line 89\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m materi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# editorに入力するテキストを作成\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m system_message, human_message \u001b[38;5;241m=\u001b[39m MakeMessage(title,fname \u001b[38;5;241m=\u001b[39m materi)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# ストリーミングのレスポンスを生成        \u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m editor\u001b[38;5;241m.\u001b[39mstream([system_message, human_message]):\n",
      "Cell \u001b[0;32mIn[56], line 57\u001b[0m, in \u001b[0;36mMakeMessage\u001b[0;34m(title, fname)\u001b[0m\n\u001b[1;32m     54\u001b[0m     loader \u001b[38;5;241m=\u001b[39m TextLoader(fname)\n\u001b[1;32m     55\u001b[0m     data \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mpage_content())\n\u001b[1;32m     58\u001b[0m     human_message \u001b[38;5;241m=\u001b[39m HumanMessage(\n\u001b[1;32m     59\u001b[0m         content\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m記事のタイトルは\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtitle\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mです。取材内容は次のとおりです。\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdata\n\u001b[1;32m     61\u001b[0m         )\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (system_message, human_message)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "import os\n",
    "\n",
    "def GetEditor(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        wrighter = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        wrighter = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        wrighter = ChatOllama(model = \"llama3\")\n",
    "    else:\n",
    "        wrighter = None\n",
    "    return wrighter\n",
    "\n",
    "def MakeMessage(title, fname=None):\n",
    "    # システムメッセージ\n",
    "    if fname is None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    if fname is not None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルと取材内容に沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # ユーザーからの入力メッセージ\n",
    "    if fname is None:\n",
    "        human_message = HumanMessage(content=title)\n",
    "    \n",
    "    if fname is not None:\n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "        print(data.page_content())\n",
    "        human_message = HumanMessage(\n",
    "            content=(\n",
    "                \"記事のタイトルは\"+title+\"です。取材内容は次のとおりです。\"+data\n",
    "            )\n",
    "        )\n",
    "         \n",
    "    return (system_message, human_message)\n",
    "\n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        wrighter = GetEditor(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "    print(\"mode :\",mode)\n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        \n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "\n",
    "        materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\\n\")\n",
    "        \n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakeMessage(title,fname = materi)\n",
    "        \n",
    "        # ストリーミングのレスポンスを生成        \n",
    "        for chunk in wrighter.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3bbb13e7-5886-463a-88ef-8ad6ab5df9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode : openai\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " 世界一の美女\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プロンプト作成完了\n",
      "タイトル：世界一の美女 – 亜実ちゃんの魅力に迫る\n",
      "\n",
      "皆さん、美女と言ったら何を思い浮かべますか？スタイル？容姿？それとも、内面の美しさでしょうか。今回は、私が知る限りの「世界一の美女」に出会ったので、その魅力をご紹介します。彼女の名前は亜実ちゃん。彼女の素敵な魅力と、普段の魅力的な生活をご紹介したいと思います。\n",
      "\n",
      "まず亜実ちゃんの一番の特徴といえば、黒くて長いツヤツヤの髪！彼女の髪は、まるでサラサラな絹のようで、その美しさは誰もが振り返るほど。彼女は、自然な黒さを大切にしていて、ヘアカラーや過度なケアは一切なし。そんな彼女の髪を見ていると、つい触りたくなっちゃいます。実は、私も長い髪を持つ友人がいるんですが、亜実ちゃんの髪はその子の髪よりさらに美しいと感じました。\n",
      "\n",
      "続いて、亜実ちゃんの服のセンスも見逃せません。彼女は普段からオシャレを楽しんでいて、カジュアルな日でも自分らしさを捨てないスタイルが素敵なんです。彼女が着る服は、どれも流行を押さえつつも、どこか彼女の個性を感じさせるアイテムばかり。友人たちも彼女のファッションを真似したいと口々に言っています。私も最近、彼女にコーディネートのアドバイスをもらったところ、周りの反応も良くなり、少し自信が持てるようになりました！\n",
      "\n",
      "さて、彼女の魅力のもう一つのポイントは「美味しい料理を作れる」ということです。亜実ちゃんは料理が得意で、友人を家に招いておもてなしをするのが好きなんだとか。ある日、私も彼女の料理教室に参加させてもらったのですが、彼女が手際よく作る料理はどれも絶品！特に、自家製のパスタとデザートのティラミスが最高でした。作る過程を見ているだけでも楽しかったし、運良く私も少しお手伝いさせてもらうことができたんです。料理を通じて彼女の気配りや優しさも感じました。\n",
      "\n",
      "亜実ちゃんは、ただの美しさを持つだけではなく、内面からも魅力があふれていて、周囲の人たちも彼女に惹きつけられる理由がよくわかります。彼女の素敵さは、外見だけでなく、人間性や性格からも滲み出ているんです。\n",
      "\n",
      "そういえば、皆さんは「世界一の美女」と聞くと、どんなイメージを思い描きますか？そこに亜実ちゃんのような魅力が詰まっているのかもしれませんね。皆さんにもそんな「世界一の美女」はいますか？彼女や彼らの魅力を教えてくれると、私もワクワクしちゃいます。\n",
      "\n",
      "亜実ちゃんのように、魅力あふれる人たちが周りにいることで、私たち自身も少しずつ輝いていけるのかもしれません。これからも、彼女の素敵な部分を少しずつ吸収して、私ももう少しオシャレで魅力的な人になりたいなって思っています。また、亜実ちゃんに会える日を心待ちにしながら、どんな素敵な料理を教えてもらおうか楽しみにしています。皆さんも、ぜひ自分の周りにいる「世界一の美女」を見つけて、その魅力を再発見してみてくださいね！\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " 進む晩婚化\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プロンプト作成完了\n",
      "タイトル: 進む晩婚化\n",
      "\n",
      "最近、晩婚化が進んでいるという話を耳にしますが、実際のところどうなっているのでしょうか。私自身も独り身の友人が多く、彼らの恋愛観や結婚観を聞いていると、時代の変化を感じることが多いです。そんな中、今回は26歳で独身、そしてTinderを使っている深尾さんにお話を伺ってみました。\n",
      "\n",
      "深尾さんは、半年前まで同棲をしていて、その後もTinderで新たな出会いを求めているとのことです。彼女の話を聞くと、晩婚化の理由の一つは、自分の時間を大切にしたいと思う人が増えているからではないかと感じました。特に、同棲を経験したことで、結婚に対するイメージが変わったと彼女は言います。「同棲している時は、結婚がすぐに必要だとは思わなかった。むしろ、お互いがどうやって成長していくかを考える時間が大切だと思った」と語ってくれました。\n",
      "\n",
      "深尾さんは、今Tinderを利用して新しい出会いを求めていますが、最初は「本当に出会えるのかな？」と不安だったそうです。しかし、実際に使ってみると、同じような考えを持つ人や、趣味が合う人と気軽に出会えることが楽しいと感じているようです。現代ではSNSやマッチングアプリを使った出会いが一般的になってきているのも、晩婚化を後押ししている要因かもしれません。\n",
      "\n",
      "心のどこかに「結婚はまだ先でいいかな」という気持ちがあるという深尾さんですが、友達から「いつ結婚するの？」というプレッシャーを受けることもしばしばあるようです。「みんなが早く結婚していく中、自分だけ取り残されているような気持ちになる時もある」と正直に語ってくれました。その一方で、自分のやりたいことや、キャリアに集中できる時間が増えるのは良いことだと感じているとのこと。\n",
      "\n",
      "また、晩婚化が進む中で、結婚に対する価値観も変わってきているのが感じられます。以前は、結婚したら子供を持つのが自然という考えが主流だったと思いますが、最近では「結婚しない選択肢」や「子供を持たない選択肢」も増えているようです。深尾さんも、「結婚しなくても幸せに暮らしている人はたくさんいるし、価値観は多様化しているんだなと感じる」と言っています。\n",
      "\n",
      "彼女の考え方には共感できるところが多いです。私自身も、結婚に対してのプレッシャーを感じることがあったり、逆に自分の人生を大切にしたいという気持ちが強くなったりと、複雑な気持ちを抱えていることがあります。\n",
      "\n",
      "さて、深尾さんの話を通して、晩婚化が進む現代において、自分自身の幸せとは何かを考えるヒントが得られたのではないでしょうか。あなたは、結婚についてどのように考えていますか？この問いかけを通じて、お互いの価値観や年代を超えた意見交換ができれば嬉しいですね。\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " 金を水銀に接触させると……？　捕食シーンのような“驚きの実験結果”が4600万再生超え「金が餌になるペットみたい」\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プロンプト作成完了\n",
      "タイトル: 金を水銀に接触させると……？ 捕食シーンのような“驚きの実験結果”が4600万再生超え「金が餌になるペットみたい」\n",
      "\n",
      "最近、YouTubeで発表された驚くべき実験動画が話題をさらっています。2021年に公開された「NileRed」の動画がなんと4600万再生を突破し、その内容がじわじわと注目を集めているんです。この実験は、なんと金と水銀を組み合わせるというもので、その反応がまるで捕食の様子を表しているといいます。\n",
      "\n",
      "金と水銀の組み合わせ、と聞いて「それってどうなるの？」と思う方も多いでしょう。実験の中では、金箔が水銀に徐々に取り込まれる様子が映し出されます。この反応の過程で、水銀は金とアマルガムという合金を形成すると言われていて、このプロセスがとにかく目を引くんです。まるで水銀が金を飲み込んでいくかのような映像は、どこかシュールであり、見る人の好奇心を刺激します。\n",
      "\n",
      "視聴者の中には、「金を吸い込むブラックホール」というコメントを残す人もいれば、「金が水銀に餌として食べられている！」と表現する人も。まるで水銀がペットのように金を包み込んでいる様子は、興味深くもあり、ちょっと面白いですよね。\n",
      "\n",
      "私自身、この実験映像を見たときの衝撃が忘れられません。学生時代に化学実験をいくつかやったけど、こんなに魅力的な反応は見たことがなかったので、思わず引き込まれてしまいました。実際に手元で見ることができたら、どんな感覚なんだろうと思います。\n",
      "\n",
      "動画の中での水銀の動きは実際に見ることができないので、想像するしかないですが、時間が経つにつれて金が「ごちそう」になっていく様子が想像できてしまうからこそ、さらに興味が湧くんですよね。ネット上での反響も大きく、実験の詳細についての議論も広がっています。\n",
      "\n",
      "さて、みなさんはこの実験を見て、どんな感想を持ちましたか？金と水銀の驚くべき反応を目の当たりにすることで、化学の世界の魅力に触れるいい機会になるでしょう。科学は身近にあり、広がりを持っている。こうした刺激的な実験を通じて、もっと深く科学に触れてみたくなる気持ちを抱えている方も多いのではないでしょうか。\n",
      "\n",
      "今後もこのような新しい実験が続々と公開され、科学が私たちの日常にもっと深く根付いていくことを期待するばかりです。金が水銀に溶け込む様子を見たことで、自分の中にある好奇心を再確認できたような気がします。科学の神秘、ぜひ皆さんも楽しんでくださいね！\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[65], line 79\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# 入力テキストの作成と記事生成\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# ユーザーから記事タイトルの入力\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m============================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m記事のタイトルを入力してください\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mesc\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mを入力して終了]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m============================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mesc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m終了します。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "def GetEditor(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        wrighter = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        wrighter = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        wrighter = ChatOllama(model = \"llama3\")\n",
    "    else:\n",
    "        wrighter = None\n",
    "    return wrighter\n",
    "\n",
    "def MakeMessage(title, fname=None):\n",
    "    # システムメッセージ\n",
    "    if fname is None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    if fname is not None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルと取材内容に沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # ユーザーからの入力メッセージ\n",
    "    if fname is None:\n",
    "        human_message = HumanMessage(content=title)\n",
    "    \n",
    "    if fname is not None:\n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "        human_message = HumanMessage(\n",
    "            content=(\n",
    "                \"記事のタイトルは\"+title+\"です。取材内容は次のとおりです。\"+data[0].page_content\n",
    "            )\n",
    "        )\n",
    "    print(\"プロンプト作成完了\")     \n",
    "    return (system_message, human_message)\n",
    "\n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        wrighter = GetEditor(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "    print(\"mode :\",mode)\n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        \n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "\n",
    "        materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\\n\")\n",
    "        \n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakeMessage(title,fname = materi)\n",
    "        \n",
    "        # ストリーミングのレスポンスを生成        \n",
    "        for chunk in wrighter.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b994a073-5642-418d-abee-47402190341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode : openai\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " test\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プロンプト作成完了\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "21 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=AIMessage(content='最近...66-8919-cf4e570e035b-0'), input_type=AIMessage]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].0.str\n  Input should be a valid string [type=string_type, input_value=('content', '最近、You...みたいですね。'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('content', '最近、You...みたいですね。'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].1.str\n  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].1.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].2.str\n  Input should be a valid string [type=string_type, input_value=('response_metadata', {'f...rint': 'fp_bd83329f63'}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].2.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {'f...rint': 'fp_bd83329f63'}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].3.str\n  Input should be a valid string [type=string_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].3.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].4.str\n  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].4.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].5.str\n  Input should be a valid string [type=string_type, input_value=('id', 'run-60a5ca7f-c299...66-8919-cf4e570e035b-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].5.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('id', 'run-60a5ca7f-c299...66-8919-cf4e570e035b-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].6.str\n  Input should be a valid string [type=string_type, input_value=('example', False), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].6.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('example', False), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].7.str\n  Input should be a valid string [type=string_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].7.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].8.str\n  Input should be a valid string [type=string_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].8.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].9.str\n  Input should be a valid string [type=string_type, input_value=('usage_metadata', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].9.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('usage_metadata', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 135\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[69], line 126\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m raw_article \u001b[38;5;241m=\u001b[39m MakeArticle(wrighter, system_message, human_message)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# 編集者によって記事がプロンプトを守っているか確認\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m CheckArticle(wrighter, raw_article)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# ストリーミングのレスポンスを生成        \u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m wrighter\u001b[38;5;241m.\u001b[39mstream([system_message, human_message]):\n",
      "Cell \u001b[0;32mIn[69], line 88\u001b[0m, in \u001b[0;36mCheckArticle\u001b[0;34m(editor, article)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     system_message \u001b[38;5;241m=\u001b[39m SystemMessage(\n\u001b[1;32m     77\u001b[0m         content\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mあなたはウェブエディターの編集者です。次の条件が正しく守られているかを判断してください。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m         )\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 88\u001b[0m     human_message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39m(article))\n\u001b[1;32m     90\u001b[0m     judge \u001b[38;5;241m=\u001b[39m editor\u001b[38;5;241m.\u001b[39minvoke(system_message, human_message)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(judge)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/messages/human.py:56\u001b[0m, in \u001b[0;36mHumanMessage.__init__\u001b[0;34m(self, content, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     49\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pass in content as positional arg.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        content: The string contents of the message.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        kwargs: Additional fields to pass to the message.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mcontent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/messages/base.py:76\u001b[0m, in \u001b[0;36mBaseMessage.__init__\u001b[0;34m(self, content, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pass in content as positional arg.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m        content: The string contents of the message.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m        kwargs: Additional fields to pass to the\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mcontent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mValidationError\u001b[0m: 21 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=AIMessage(content='最近...66-8919-cf4e570e035b-0'), input_type=AIMessage]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].0.str\n  Input should be a valid string [type=string_type, input_value=('content', '最近、You...みたいですね。'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('content', '最近、You...みたいですね。'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].1.str\n  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].1.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].2.str\n  Input should be a valid string [type=string_type, input_value=('response_metadata', {'f...rint': 'fp_bd83329f63'}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].2.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {'f...rint': 'fp_bd83329f63'}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].3.str\n  Input should be a valid string [type=string_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].3.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].4.str\n  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].4.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].5.str\n  Input should be a valid string [type=string_type, input_value=('id', 'run-60a5ca7f-c299...66-8919-cf4e570e035b-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].5.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('id', 'run-60a5ca7f-c299...66-8919-cf4e570e035b-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].6.str\n  Input should be a valid string [type=string_type, input_value=('example', False), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].6.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('example', False), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].7.str\n  Input should be a valid string [type=string_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].7.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].8.str\n  Input should be a valid string [type=string_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].8.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type\ncontent.list[union[str,dict[any,any]]].9.str\n  Input should be a valid string [type=string_type, input_value=('usage_metadata', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/string_type\ncontent.list[union[str,dict[any,any]]].9.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('usage_metadata', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.8/v/dict_type"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def GetEditor(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        wrighter = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        wrighter = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        wrighter = ChatOllama(model = \"llama3\")\n",
    "    else:\n",
    "        wrighter = None\n",
    "    return wrighter\n",
    "\n",
    "def MakeMessage(title, fname=None):\n",
    "    # システムメッセージ\n",
    "    if fname is None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    if fname is not None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルと取材内容に沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # ユーザーからの入力メッセージ\n",
    "    if fname is None:\n",
    "        human_message = HumanMessage(content=title)\n",
    "    \n",
    "    if fname is not None:\n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "        human_message = HumanMessage(\n",
    "            content=(\n",
    "                \"記事のタイトルは\"+title+\"です。取材内容は次のとおりです。\"+data[0].page_content\n",
    "            )\n",
    "        )\n",
    "    print(\"プロンプト作成完了\")     \n",
    "    return (system_message, human_message)\n",
    "\n",
    "# 記事を作成\n",
    "def MakeArticle(wrighter, system_message, human_message):\n",
    "\n",
    "    # ストリーミングのレスポンスを生成        \n",
    "    response = wrighter.invoke([system_message, human_message])\n",
    "\n",
    "    return response\n",
    "\n",
    "def CheckArticle(editor, article):\n",
    "\n",
    "    while True:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "                \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "                \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "                \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "                \"4. Markdownの形式で記述されていないこと\"\n",
    "                \"5. 記事が日本語で記述されていること\"\n",
    "                \"上記の全てが守られている場合にTrue, 守られていない場合はFalseノミを出力して下さい\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        human_message = HumanMessage(content=(article))\n",
    "    \n",
    "        judge = editor.invoke(system_message, human_message)\n",
    "\n",
    "        print(judge)\n",
    "\n",
    "        return judge\n",
    "        \n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        wrighter = GetEditor(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "    print(\"mode :\",mode)\n",
    "    \n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "            \n",
    "        # 記事作成に使用する情報\n",
    "        materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\\n\")\n",
    "        \n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakeMessage(title, fname = materi)\n",
    "\n",
    "        # raw_articleを作成\n",
    "        raw_article = MakeArticle(wrighter, system_message, human_message)\n",
    "        \n",
    "        # 編集者によって記事がプロンプトを守っているか確認\n",
    "        CheckArticle(wrighter, raw_article)\n",
    "        \n",
    "        # ストリーミングのレスポンスを生成        \n",
    "        for chunk in wrighter.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acd2f8c-7480-46f3-ae03-0d48905de730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " google\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode : google\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " test\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プロンプト作成完了\n",
      "content='あなたはウェブエディターです。1500文字程度で次のタイトルと取材内容に沿った記事を作成してください。記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。記事は必ず日本語で作成してください。' additional_kwargs={} response_metadata={}\n",
      "content='記事のタイトルはtestです。取材内容は次のとおりです。深尾水銀に金を溶かす実験動画が注目されています。動画はYouTubeチャンネル「NileRed」により2021年に公開され、4600万再生を突破しました。水銀は金と反応し、アマルガムという合金を形成するため、金箔がゆっくりと水銀に取り込まれます。その様子が捕食のようで、視聴者から「金を吸い込むブラックホール」といったコメントが寄せられました。水銀の反応は止まらず、どのくらい金を溶かせるのか興味を引いています。' additional_kwargs={} response_metadata={}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'from_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 140\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 140\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[4], line 126\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m system_message, human_message \u001b[38;5;241m=\u001b[39m MakeMessage(title, fname \u001b[38;5;241m=\u001b[39m materi)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# raw_articleを作成\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m raw_article \u001b[38;5;241m=\u001b[39m MakeArticle(wrighter, system_message, human_message)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# 編集者によって記事がプロンプトを守っているか確認\u001b[39;00m\n\u001b[1;32m    129\u001b[0m CheckArticle(wrighter, raw_article)\n",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m, in \u001b[0;36mMakeArticle\u001b[0;34m(wrighter, system_message, human_message)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(system_message)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(human_message)\n\u001b[0;32m---> 72\u001b[0m response \u001b[38;5;241m=\u001b[39m wrighter\u001b[38;5;241m.\u001b[39minvoke([system_message, human_message])\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:790\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    784\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    789\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:647\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    646\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 647\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    648\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    649\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    651\u001b[0m ]\n\u001b[1;32m    652\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:637\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 637\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    638\u001b[0m                 m,\n\u001b[1;32m    639\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    640\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    641\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    642\u001b[0m             )\n\u001b[1;32m    643\u001b[0m         )\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:855\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    856\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    857\u001b[0m         )\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:951\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    927\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    939\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    940\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    941\u001b[0m         messages,\n\u001b[1;32m    942\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    950\u001b[0m     )\n\u001b[0;32m--> 951\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[1;32m    952\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    954\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[1;32m    955\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    836\u001b[0m     request,\n\u001b[1;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    840\u001b[0m )\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/exceptions.py:616\u001b[0m, in \u001b[0;36mfrom_grpc_error\u001b[0;34m(rpc_exc)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# NOTE(lidiz) All gRPC error shares the parent class grpc.RpcError.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# However, check for grpc.RpcError breaks backward compatibility.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    614\u001b[0m     grpc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rpc_exc, grpc\u001b[38;5;241m.\u001b[39mCall)\n\u001b[1;32m    615\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m _is_informative_grpc_error(rpc_exc):\n\u001b[0;32m--> 616\u001b[0m     details, err_info \u001b[38;5;241m=\u001b[39m _parse_grpc_error_details(rpc_exc)\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_grpc_status(\n\u001b[1;32m    618\u001b[0m         rpc_exc\u001b[38;5;241m.\u001b[39mcode(),\n\u001b[1;32m    619\u001b[0m         rpc_exc\u001b[38;5;241m.\u001b[39mdetails(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         error_info\u001b[38;5;241m=\u001b[39merr_info,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/exceptions.py:564\u001b[0m, in \u001b[0;36m_parse_grpc_error_details\u001b[0;34m(rpc_exc)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_grpc_error_details\u001b[39m(rpc_exc):\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m         status \u001b[38;5;241m=\u001b[39m rpc_status\u001b[38;5;241m.\u001b[39mfrom_call(rpc_exc)\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# workaround\u001b[39;00m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [], \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'from_call'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def GetEditor(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        wrighter = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        wrighter = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        wrighter = ChatOllama(model = \"llama3\")\n",
    "    else:\n",
    "        wrighter = None\n",
    "    return wrighter\n",
    "\n",
    "def MakeMessage(title, fname=None):\n",
    "    # システムメッセージ\n",
    "    if fname is None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    if fname is not None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルと取材内容に沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # ユーザーからの入力メッセージ\n",
    "    if fname is None:\n",
    "        human_message = HumanMessage(content=title)\n",
    "    \n",
    "    if fname is not None:\n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "        human_message = HumanMessage(\n",
    "            content=(\n",
    "                \"記事のタイトルは\"+title+\"です。取材内容は次のとおりです。\"+data[0].page_content\n",
    "            )\n",
    "        )\n",
    "    print(\"プロンプト作成完了\")     \n",
    "    return (system_message, human_message)\n",
    "\n",
    "# 記事を作成\n",
    "def MakeArticle(wrighter, system_message, human_message):\n",
    "\n",
    "    # ストリーミングのレスポンスを生成        \n",
    "    print(system_message)\n",
    "    print(human_message)\n",
    "    \n",
    "    response = wrighter.invoke([system_message, human_message])\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "def CheckArticle(editor, article):\n",
    "\n",
    "    while True:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "                \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "                \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "                \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "                \"4. Markdownの形式で記述されていないこと\"\n",
    "                \"5. 記事が日本語で記述されていること\"\n",
    "                \"上記の全てが守られている場合にTrue, 守られていない場合はFalseノミを出力して下さい\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(article)\n",
    "        # human_message = HumanMessage(content=(article))\n",
    "    \n",
    "        # judge = editor.invoke(system_message, human_message)\n",
    "        # print(judge)\n",
    "\n",
    "        # return judge\n",
    "        \n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        wrighter = GetEditor(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "    print(\"mode :\",mode)\n",
    "    \n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "            \n",
    "        # 記事作成に使用する情報\n",
    "        materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\\n\")\n",
    "        \n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakeMessage(title, fname = materi)\n",
    "\n",
    "        # raw_articleを作成\n",
    "        raw_article = MakeArticle(wrighter, system_message, human_message)\n",
    "        \n",
    "        # 編集者によって記事がプロンプトを守っているか確認\n",
    "        CheckArticle(wrighter, raw_article)\n",
    "        \n",
    "        # ストリーミングのレスポンスを生成        \n",
    "        # for chunk in wrighter.stream([system_message, human_message]):\n",
    "        #     if chunk.content:\n",
    "        #         print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "        print(raw_article)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32006366-39a6-4e95-b696-2dfe3959fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " google\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode : google\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " test\n",
      "記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プロンプト作成完了\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'from_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[6], line 91\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m system_message, human_message \u001b[38;5;241m=\u001b[39m MakeMessage(title,fname \u001b[38;5;241m=\u001b[39m materi)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# ストリーミングのレスポンスを生成        \u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m editor\u001b[38;5;241m.\u001b[39mstream([system_message, human_message]):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mcontent, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:422\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    417\u001b[0m         e,\n\u001b[1;32m    418\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    419\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    420\u001b[0m         ),\n\u001b[1;32m    421\u001b[0m     )\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:400\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m             chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1034\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._stream\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream\u001b[39m(\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1010\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatGenerationChunk]:\n\u001b[1;32m   1023\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m   1024\u001b[0m         messages,\n\u001b[1;32m   1025\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[0;32m-> 1034\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[1;32m   1035\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m   1036\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mstream_generate_content,\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1038\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[1;32m   1039\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m     prev_usage_metadata: UsageMetadata \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:1143\u001b[0m, in \u001b[0;36mGenerativeServiceClient.stream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m   1144\u001b[0m     request,\n\u001b[1;32m   1145\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m   1146\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1147\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m   1148\u001b[0m )\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:174\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[1;32m    171\u001b[0m         result, prefetch_first_result\u001b[38;5;241m=\u001b[39mprefetch_first\n\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/exceptions.py:616\u001b[0m, in \u001b[0;36mfrom_grpc_error\u001b[0;34m(rpc_exc)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# NOTE(lidiz) All gRPC error shares the parent class grpc.RpcError.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# However, check for grpc.RpcError breaks backward compatibility.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    614\u001b[0m     grpc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rpc_exc, grpc\u001b[38;5;241m.\u001b[39mCall)\n\u001b[1;32m    615\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m _is_informative_grpc_error(rpc_exc):\n\u001b[0;32m--> 616\u001b[0m     details, err_info \u001b[38;5;241m=\u001b[39m _parse_grpc_error_details(rpc_exc)\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_grpc_status(\n\u001b[1;32m    618\u001b[0m         rpc_exc\u001b[38;5;241m.\u001b[39mcode(),\n\u001b[1;32m    619\u001b[0m         rpc_exc\u001b[38;5;241m.\u001b[39mdetails(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         error_info\u001b[38;5;241m=\u001b[39merr_info,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/exceptions.py:564\u001b[0m, in \u001b[0;36m_parse_grpc_error_details\u001b[0;34m(rpc_exc)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_grpc_error_details\u001b[39m(rpc_exc):\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m         status \u001b[38;5;241m=\u001b[39m rpc_status\u001b[38;5;241m.\u001b[39mfrom_call(rpc_exc)\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# workaround\u001b[39;00m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [], \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'from_call'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "import os\n",
    "\n",
    "# APIキーを環境変数として設定\n",
    "\n",
    "def GetEditor(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        editor = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        editor = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        editor = ChatOllama(model = \"llama3\")\n",
    "    else:\n",
    "        editor = None\n",
    "    return editor\n",
    "\n",
    "def MakeMessage(title, fname=None):\n",
    "    # システムメッセージ\n",
    "    if fname is None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    if fname is not None:\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"あなたはウェブエディターです。1500文字程度で次のタイトルと取材内容に沿った記事を作成してください。\"\n",
    "                \"記事は適度にフランクな口調で作成してください。記事中に読者への問いかけを一つだけ入れてください。\"\n",
    "                \"記事中に身近な話題の場合は体験談も入れてください。Markdownの形式で記述しないでください。\"\n",
    "                \"記事は必ず日本語で作成してください。\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # ユーザーからの入力メッセージ\n",
    "    if fname is None:\n",
    "        human_message = HumanMessage(content=title)\n",
    "    \n",
    "    if fname is not None:\n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "        human_message = HumanMessage(\n",
    "            content=(\n",
    "                \"記事のタイトルは\"+title+\"です。取材内容は次のとおりです。\"+data[0].page_content\n",
    "            )\n",
    "        )\n",
    "    print(\"プロンプト作成完了\")     \n",
    "    return (system_message, human_message)\n",
    "\n",
    "def main():\n",
    "    # editorの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        editor = GetEditor(mode)\n",
    "        if editor is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "    print(\"mode :\",mode)\n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        \n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "\n",
    "        materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合は入力せずにエンターを入力してください\\n\")\n",
    "        \n",
    "        # editorに入力するテキストを作成\n",
    "        system_message, human_message = MakeMessage(title,fname = materi)\n",
    "        \n",
    "        # ストリーミングのレスポンスを生成        \n",
    "        for chunk in editor.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bf0b455-ba1d-48d8-8187-53afcef2fc20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "記事作成に使用するモデル: openai\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " 世界一の美女\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タイトル    　　 　:  世界一の美女\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\n",
      " test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用したファイル名　:  test.txt\n",
      "### 世界一の美女 - 亜実ちゃんの魅力に迫る\n",
      "\n",
      "こんにちは！今日は、個人的に「世界一の美女」と思っている亜実ちゃんについてお話ししたいと思います。美しさって外見だけじゃなくて、内面やその人の持つ雰囲気にも影響されるもの。それを体現しているのが亜実ちゃんです。彼女の黒髪と料理の腕前に注目してみましょう。\n",
      "\n",
      "まず、亜実ちゃんの黒髪。彼女は自然な黒髪で、まるで黒曜石のように艶やかで、どこか神秘的な魅力があります。人を惹きつける不思議なオーラが漂っていて、実際に会うとその美しさに思わず目を奪われてしまうんです。あなたも黒髪の美しさに憧れたこと、ありませんか？私は正直、亜実ちゃんを見たときに、「こんなに美しい髪の毛があるなら、私も黒髪に戻してみようかな」と思ったことがあります。\n",
      "\n",
      "亜実ちゃんは真面目でありながらも、みんなを笑顔にする明るい性格。彼女と話していると、自然と心が和らぎます。そんな彼女は、料理も得意なのです。彼女が腕を振るった料理は、見た目も華やかで、味も絶品。私はこの前、亜実ちゃんの手作り料理をいただく機会があったのですが、その味はまるで高級レストランにいるかのようでした。特に彼女の得意料理である「ビーフストロガノフ」は、ふんわりとした肉とクリーミーなソースが絶妙に絡み合い、一口食べただけで幸せな気持ちになりました。\n",
      "\n",
      "料理の魅力は、その味だけでなく、愛情が込められているところでしょう。亜実ちゃんは、料理を通じて「食べる人を幸せにしたい」という気持ちを持っているようです。そんな彼女の料理を食べることで、心まで満たされるのを実感しました。あなたも、誰かに料理を振る舞って、その人を喜ばせたいと思ったことがありますか？あるいは、自分が誰かの料理を食べて、感動した経験ってありますよね。\n",
      "\n",
      "さて、亜実ちゃんに話を戻しましょう。彼女の周りには、いつも笑顔が絶えません。友人たちと集まる際には、亜実ちゃんが料理を作ってくれるので、皆でワイワイ言いながら食卓を囲むのがとても楽しみです。料理を作ることで、コミュニケーションが生まれるって素敵ですよね。亜実ちゃんがキッチンに立っている姿を見ていると、料理って単なる食事じゃなくて、心をつなぐ大切な時間だと感じます。\n",
      "\n",
      "最後に、亜実ちゃんの魅力は黒髪と料理だけではありません。彼女の持つ優しさや思いやりの気持ちも、周囲の人々を魅了してやみません。美しさは、外見だけでなく、内面からも滲み出るものだと、亜実ちゃんを通じて改めて思いました。\n",
      "\n",
      "以上、私の大好きな亜実ちゃんについて書いてみましたが、あなたも身近にそんな素敵な人、いますか？皆さんも、周りの大切な人の魅力を再確認してみるのもいいかもしれませんよ！\n",
      "===============================================================================================================================\n",
      "以下の条件に基づいて文章を修正します。\n",
      "\n",
      "---\n",
      "\n",
      "### 世界一の美女 - 亜実ちゃんの魅力に迫る\n",
      "\n",
      "今回は私が「世界一の美女」と考える亜実ちゃんについてお話ししたいと思います。美しさとは外見だけにとどまらず、内面やその人の持つ雰囲気にも深く関わっています。それをまさに体現しているのが亜実ちゃんです。彼女の黒髪と料理の腕前に注目してみましょう。\n",
      "\n",
      "まず、彼女の黒髪についてですが、亜実ちゃんは自然なしなやかな黒髪を持っており、その輝きはまるで黒曜石のようです。どこか神秘的な魅力があり、実際に会うとその美しさに思わず目を奪われてしまいます。読者の方も、黒髪の持つ美しさに心惹かれたことはありませんか？私個人としても、亜実ちゃんを見た際に「これほど美しい髪があるなら、私も黒髪に戻してみようか」と感じたことがあります。\n",
      "\n",
      "亜実ちゃんは真面目でありながら、周囲を笑顔にする明るい性格の持ち主です。彼女と会話を交わすと、自然に心が穏やかになります。さらに、料理に関しても彼女は非常に優れた才能を持っています。実際に、亜実ちゃんが腕を振るった料理は、見た目にも華やかで、味も絶品です。私が最近、亜実ちゃんの手作り料理をいただく機会がありましたが、その味は高級レストランにいるかのような感動を与えてくれました。特に彼女の得意料理である「ビーフストロガノフ」は、一口食べるだけで、とても幸せな気持ちになれました。\n",
      "\n",
      "料理の魅力は味だけでなく、そこに込められた愛情にもあります。亜実ちゃんは料理を通じて「食べる人を幸せにしたい」という強い思いを持っているようです。彼女の料理をいただくことで、心まで満たされる実感を得ました。あなたも、誰かに手料理を振る舞うことでその人を喜ばせたいと感じたことはありませんか？また、自分が他の誰かの料理を食べて感動したこともあるのではないでしょうか。\n",
      "\n",
      "さて、亜実ちゃんの話に戻りますが、彼女の周りには常に笑顔があふれています。友人たちとの集まりでは、亜実ちゃんが料理を担当してくれるので、皆で楽しく食卓を囲むことができるのがとても楽しみです。料理をすることがコミュニケーションを生む素晴らしい手段になることを、改めて感じています。亜実ちゃんのキッチンに立つ姿を見ると、料理が食事を超えた大切な時間であることに気づかされます。\n",
      "\n",
      "最後に、亜実ちゃんの魅力は黒髪と料理だけではありません。彼女が持つ優しさや思いやりの心も、周囲の人々を惹きつけてやみません。美しさは外見だけでなく、内面からも滲み出てくるものであると、亜実ちゃんを通じて再確認しました。\n",
      "\n",
      "以上、私の大好きな亜実ちゃんについてお話ししましたが、皆さんの周りには、同じように素敵な人はいませんか？周りの大切な人々の魅力をもう一度確認してみるのも良いかもしれません。\n",
      "\n",
      "--- \n",
      "\n",
      "この修正により、指定されたすべての条件を満たしました。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " ちいかわのうさぎに迫る\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タイトル    　　 　:  ちいかわのうさぎに迫る\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\n",
      " None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用したファイル名　:  None\n",
      "### ちいかわのうさぎに迫る\n",
      "\n",
      "最近、アニメやマンガの世界で「ちいかわ」がかなりの人気を集めているの、知ってましたか？小さくてかわいいキャラクターたちが織りなす日常は、見ているだけで心が和みますよね。その中でも特に注目したいのが「うさぎ」！彼女は見た目がとても愛らしいだけでなく、ちょっとしたクセや個性を持っています。今回は、そんなちいかわのうさぎに迫ってみましょう！\n",
      "\n",
      "まず、うさぎの特徴について語ると、彼女はほんとに可愛いらしい。ピンクのほっぺに、フワフワの耳。見た瞬間に「キュン！」となること間違いなしですよね。皆さんは、うさぎを見てどんな感情が湧いてきますか？私の場合、こんなにも可愛いキャラクターがいることに心が癒され、自分ももっと優しくなりたい気分になります。\n",
      "\n",
      "ちいかわのストーリーの中で、うさぎはどちらかというとおっとりとした性格。それなのに時折見せる意地っ張りな一面が、彼女をさらに魅力的にしています。理屈や理不尽に対して直ぐに反発する反応は、私たちが日常的に感じる不満や葛藤を映し出しているようで、共感を覚えますよね。\n",
      "\n",
      "私自身、ある日仕事でストレスが溜まっていた時、ちいかわのアニメを観たんです。特にうさぎのエピソードが心を救ってくれました。彼女が他のキャラクターと一緒に助け合っている姿を見て、私も周りの友達と支え合うことが大事だなと感じました。皆さんにもそんな体験、ありませんか？\n",
      "\n",
      "また、うさぎの友達である「ちいかわ」たちとのやり取りも見逃せません。彼女はみんなと一緒に遊んだり、時にはちょっとした意地を張ったりして、友情を深めていく様子が描かれています。思い出してみてください、小さい頃友達と遊びながら時々喧嘩したこと、でもすぐに仲直りしたあの感じ！あの無邪気さが、うさぎにも表現されていることが多いですよね。このような友情の描写、皆さんはどう感じますか？\n",
      "\n",
      "さらに、ちいかわのうさぎは、日々の生活の中での小さな努力と成長も見せてくれます。何かに一生懸命取り組んでいる姿は、私たちにも勇気を与えてくれます。「私も頑張らなきゃ！」って思わせてくれる存在なんです。実際、挑戦することの大切さを教えてくれるのが、うさぎの一番の魅力かもしれません。\n",
      "\n",
      "では、最後にちょっと考えてみたいのですが、ちいかわのうさぎを通じて、あなたは何を学びましたか？私のように、自分の周りの人と助け合ったり、日常の小さな幸せに目を向けたりしているのでしょうか。彼女の存在が、私たちの生活にどれほど大きな影響を与えているか改めて感じさせられます。\n",
      "\n",
      "この春、ちいかわのうさぎを更に知ることで、あなたの心に優しさや癒しをもたらしてくれることを願っています。ぜひ、彼女の世界に触れてみてください！あなたの心に、素敵な感情が芽生えますように。\n",
      "===============================================================================================================================\n",
      "以下の条件に基づいて、文章を修正いたしました。\n",
      "\n",
      "1. 記事の文体がフランクすぎないように調整しました。\n",
      "2. 読者への問いかけを含めました。\n",
      "3. 身近な話題の場合、体験談を取り入れました。\n",
      "4. Markdown形式を使わず、通常の文章形式にしました。\n",
      "5. 日本語で記述されています。\n",
      "\n",
      "---\n",
      "\n",
      "### ちいかわのうさぎに迫る\n",
      "\n",
      "最近、アニメやマンガの世界で「ちいかわ」がかなりの人気を集めています。皆さんはこの現象を知っていましたか？小さくて可愛いキャラクターたちが織りなす日常は、見ているだけで心が和みます。その中でも特に注目したいのが「うさぎ」です。彼女は見た目がとても愛らしく、ちょっとしたクセや個性を持っています。今回は、そんなちいかわのうさぎについて詳しく見ていきましょう。\n",
      "\n",
      "うさぎの特徴を挙げると、何と言ってもその可愛らしさです。ピンクのほっぺやフワフワの耳を持ち、見た瞬間には愛おしさを感じること間違いありません。皆さんは、うさぎを見たときにどのような気持ちになりますか？私自身、彼女の存在に癒され、また自分も優しくなりたいと感じることが多いです。\n",
      "\n",
      "ちいかわのストーリーでは、うさぎはおとなしめな性格を持っていますが、時には意地っ張りな一面を見せることで、彼女のキャラクターに深みを与えています。理不尽に対して反発するその姿勢は、私たちの日常生活で感じる不満や葛藤を象徴しているようで、共感を覚えます。\n",
      "\n",
      "私がストレスを感じていたある日のこと、ちいかわのアニメを観る機会がありました。特にうさぎのエピソードが心に響きました。彼女が他のキャラクターと助け合う姿を見て、私にも友人との支え合いが大切だと改めて気づかされました。皆さんも、そういった経験を持ったことはありませんか？\n",
      "\n",
      "また、うさぎが「ちいかわ」たちと繰り広げるやり取りも魅力的です。彼女は友達と遊びながら時には喧嘩をし、すぐに仲直りする。これがまさに友情の本質を描いていると思います。皆さんも、小さい頃に友達と遊んでいて喧嘩したことを思い出しませんか？その後の和解もまた、無邪気な思い出として心に残っています。\n",
      "\n",
      "さらに、ちいかわのうさぎは、日常生活の中での小さな努力と成長を示しています。何かに一生懸命取り組む姿勢は、私たちにも勇気を与えてくれます。「私も頑張らなきゃ！」と思わせてくれる存在です。挑戦することの大切さを教えてくれるのが、うさぎの持つ魅力かもしれません。\n",
      "\n",
      "最後に、ちいかわのうさぎを通じて皆さんが何を学んだのか、少し考えてみてはいかがでしょうか。私のように、自分の周りの人々と助け合ったり、日常の小さな幸せを大切にしたりしていますか。彼女の存在が、私たちの生活にどのような影響を与えているのか、改めて感じさせられます。\n",
      "\n",
      "この春、ちいかわのうさぎをより知ることで、皆さんの心に優しさや癒しがもたらされることを願っています。ぜひ、彼女の世界に触れてみてください。あなたの心に、素敵な感情が芽生えますように。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      " esc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "終了します。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "# from langchain.schema import SystemMessage, HumanMessage #invoke()を使用するために見送り。\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "\n",
    "# APIキーを環境変数として設定\n",
    "def GetLlm(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7, streaming=True)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        llm = ChatOllama(model = \"llama3\",streaming=True)\n",
    "    else:\n",
    "        llm = None\n",
    "    return llm\n",
    "\n",
    "def MakePrompt(title, fname=None):\n",
    "    # プロンプトのテンプレートの作成\n",
    "    if fname is None:\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"記事のタイトルは{title}です。\"\n",
    "            )\n",
    "    if fname is not None:\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"記事のタイトルは{title}です。\"\n",
    "            \"取材内容は次のとおりです{data}\"\n",
    "            )\n",
    "    \n",
    "    # プロンプトの作成\n",
    "    if fname is None:\n",
    "        prompt = temp.invoke({\"title\": title})\n",
    "    \n",
    "    \n",
    "    if fname is not None:\n",
    "        # 記事作成の材料の読み込み    \n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "        \n",
    "        prompt = temp.invoke({\"title\": title, \"data\": data[0].page_content})\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# 記事を作成\n",
    "def MakeArticle(wrighter, prompt):\n",
    "\n",
    "    # ストリーミングのレスポンスを生成\n",
    "    response = wrighter.invoke(prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def CheckArticle(editor, article, fname=None):\n",
    "\n",
    "    if fname is None:\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"あなたはウェブエディターの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "            \"1. 記事の文体がフランクすぎないこと\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"上記の全条件が守られている文章に修正して下さい。ただし、タイトルは変更しないでください。\"\n",
    "            \"{article}\"\n",
    "            )\n",
    "        prompt = temp.invoke({\"article\": article})\n",
    "    \n",
    "    if fname is not None:\n",
    "        \n",
    "        # 記事作成の材料の読み込み    \n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "        \n",
    "        # プロンプトの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"あなたはウェブエディターの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "            \"1. 記事の文体がフランクすぎないこと\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. 記事が形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"6. 記事が{materi}に沿って作られていること\"\n",
    "            \"上記の全条件が守られている記事に修正して下さい。出力は記事のみを出力して下さい\"\n",
    "            \"{article}\"\n",
    "            )\n",
    "    \n",
    "        prompt = temp.invoke({\"article\": article, \"materi\": article})\n",
    "    \n",
    "    new_article = editor.invoke(prompt)\n",
    "    \n",
    "    return new_article\n",
    "        \n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        wrighter = GetLlm(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "\n",
    "    print(\"記事作成に使用するモデル:\" , mode)\n",
    "    \n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n============================================\\n\")\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "        \n",
    "        print(\"タイトル    　　 　: \", title)\n",
    "        \n",
    "        # 情報の追加\n",
    "        while True:\n",
    "            materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\\n\")\n",
    "            if materi == \"None\":\n",
    "                materi = None\n",
    "                break\n",
    "            if os.path.isfile(materi):\n",
    "                break\n",
    "\n",
    "            print(\"[Error]ファイル\"+materi+\"が見つかりません。\")\n",
    "\n",
    "        print(\"使用したファイル名　: \", materi)\n",
    "        \n",
    "        # wrighterに入力するテキストを作成\n",
    "        prompt = MakePrompt(title, fname=materi)                \n",
    "        \n",
    "        # editorの作成\n",
    "        editor = wrighter\n",
    "        \n",
    "        # raw_articleを作成\n",
    "        article = MakeArticle(editor, prompt)\n",
    "        \n",
    "        # 編集者によって記事がプロンプトを守っているか確認\n",
    "        new_article = CheckArticle(wrighter, article, fname=materi)\n",
    "            \n",
    "        print(article.content)\n",
    "        print(\"===============================================================================================================================\")\n",
    "        print(new_article.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f819a283-9b31-45d4-ae01-97c51b96cbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " google\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "記事作成に使用するモデル: google\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      "タイトル    　　 　:  空飛ぶ自動車\n",
      "記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\n",
      "ファイル名         : test.txt\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'from_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 181\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mprint\u001b[39m(new_article\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 181\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[73], line 170\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m system_message, human_message \u001b[38;5;241m=\u001b[39m MakePrompt(title, fname\u001b[38;5;241m=\u001b[39mmateri)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# raw_articleを作成\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m article \u001b[38;5;241m=\u001b[39m wrighter\u001b[38;5;241m.\u001b[39minvoke([system_message, human_message])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(article\u001b[38;5;241m.\u001b[39mcontent)        \n\u001b[1;32m    172\u001b[0m editor \u001b[38;5;241m=\u001b[39m wrighter\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:790\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    784\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    789\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:647\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    646\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 647\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    648\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    649\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    651\u001b[0m ]\n\u001b[1;32m    652\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:637\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 637\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    638\u001b[0m                 m,\n\u001b[1;32m    639\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    640\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    641\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    642\u001b[0m             )\n\u001b[1;32m    643\u001b[0m         )\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:855\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    856\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    857\u001b[0m         )\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:951\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    927\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    939\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    940\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    941\u001b[0m         messages,\n\u001b[1;32m    942\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[1;32m    950\u001b[0m     )\n\u001b[0;32m--> 951\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[1;32m    952\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    954\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[1;32m    955\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    836\u001b[0m     request,\n\u001b[1;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    840\u001b[0m )\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/exceptions.py:616\u001b[0m, in \u001b[0;36mfrom_grpc_error\u001b[0;34m(rpc_exc)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# NOTE(lidiz) All gRPC error shares the parent class grpc.RpcError.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# However, check for grpc.RpcError breaks backward compatibility.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    614\u001b[0m     grpc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rpc_exc, grpc\u001b[38;5;241m.\u001b[39mCall)\n\u001b[1;32m    615\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m _is_informative_grpc_error(rpc_exc):\n\u001b[0;32m--> 616\u001b[0m     details, err_info \u001b[38;5;241m=\u001b[39m _parse_grpc_error_details(rpc_exc)\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_grpc_status(\n\u001b[1;32m    618\u001b[0m         rpc_exc\u001b[38;5;241m.\u001b[39mcode(),\n\u001b[1;32m    619\u001b[0m         rpc_exc\u001b[38;5;241m.\u001b[39mdetails(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         error_info\u001b[38;5;241m=\u001b[39merr_info,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/google/api_core/exceptions.py:564\u001b[0m, in \u001b[0;36m_parse_grpc_error_details\u001b[0;34m(rpc_exc)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_grpc_error_details\u001b[39m(rpc_exc):\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m         status \u001b[38;5;241m=\u001b[39m rpc_status\u001b[38;5;241m.\u001b[39mfrom_call(rpc_exc)\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# workaround\u001b[39;00m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [], \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'from_call'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def GetLlm(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7, streaming=True)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        llm = ChatOllama(model = \"llama3\",streaming=True)\n",
    "    else:\n",
    "        llm = None\n",
    "    return llm\n",
    "\n",
    "def MakePrompt(title, fname=None):\n",
    "    if fname is None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            )\n",
    "        # プロンプトテンプレートの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事のタイトルは{title}です。\"\n",
    "            )\n",
    "\n",
    "        # 入力メッセージの作成\n",
    "        prompt = temp.invoke({\"title\": title})\n",
    "\n",
    "    # 参考記事なしの場合\n",
    "    if fname is not None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブエディターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            )\n",
    "        # プロンプトテンプレートの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事のタイトルは{title}です。\"\n",
    "            \"取材内容は次のとおりです{data}\"\n",
    "            )\n",
    "     \n",
    "        # 記事作成の材料の読み込み    \n",
    "        loader = TextLoader(fname)\n",
    "        data   = loader.load()\n",
    "\n",
    "        # 入力メッセージの作成\n",
    "        prompt = temp.invoke({\"title\": title, \"data\": data[0].page_content})\n",
    "\n",
    "    # ヒューマンメッセージの作成\n",
    "    human_message = HumanMessage(content=prompt.to_string())\n",
    "    \n",
    "    return system_message, human_message\n",
    "    \n",
    "def CheckArticle(editor, article, fname=None):\n",
    "\n",
    "    if fname is None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブメディアの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "            \"1. 記事の文体がフランクすぎないこと\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が正確な日本語で記述されていること\"\n",
    "            \"上記の全条件が守られている文章に修正して下さい。ただし、タイトルは変更しないでください。\"\n",
    "            )\n",
    "        # プロンプトの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"{article}\"\n",
    "        )\n",
    "        \n",
    "        prompt = temp.format({\"article\": article})\n",
    "\n",
    "    if fname is not None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブエディターの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "            \"1. 記事の文体がフランクすぎないこと\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. 記事が形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"6. 記事が材料に沿って作られていること\"\n",
    "            \"上記の全条件が守られている記事に修正して下さい。出力は記事のみを出力して下さい\"\n",
    "            )        \n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "                                       \n",
    "        # プロンプトの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事の材料:{materi}\"\n",
    "            \"記事本文:{article}\"\n",
    "            )\n",
    "    \n",
    "        prompt = temp.format(materi=data, article=article)\n",
    "    # ヒューマンメッセージの作成\n",
    "    human_message = HumanMessage(content=prompt)\n",
    "\n",
    "    new_article = editor.invoke([system_message, human_message])\n",
    "    \n",
    "    return new_article\n",
    "        \n",
    "def main():\n",
    "    # wrighterの作成\n",
    "    while True:\n",
    "        mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "        wrighter = GetLlm(mode)\n",
    "        if wrighter is not None:\n",
    "            break\n",
    "        \n",
    "        print(\"対応しているモデル名を入力してください\")\n",
    "\n",
    "    print(\"記事作成に使用するモデル:\" , mode)\n",
    "    \n",
    "    # 入力テキストの作成と記事生成\n",
    "    while True:\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n\"\n",
    "                      \"記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n\"\n",
    "                      \"============================================\\n\"\n",
    "                      \"タイトル    　　 　: \"\n",
    "                     )\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "        \n",
    "        # 情報の追加\n",
    "        while True:\n",
    "            materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\\n\"\n",
    "                           \"ファイル名         :\"\n",
    "                          )\n",
    "            \n",
    "            if materi == \"None\":\n",
    "                materi = None\n",
    "                break\n",
    "            if os.path.isfile(materi):\n",
    "                break\n",
    "\n",
    "            print(\"[Error]ファイル\"+materi+\"が見つかりません。\")\n",
    "\n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakePrompt(title, fname=materi)\n",
    "        \n",
    "        # raw_articleを作成\n",
    "        article = wrighter.invoke([system_message, human_message])\n",
    "        print(article.content)        \n",
    "        editor = wrighter\n",
    "        # 編集者によって記事がプロンプトを守っているか確認\n",
    "        new_article = CheckArticle(editor, article, fname=materi)\n",
    "        \n",
    "\n",
    "        print(\"===============================================================================================================================\")\n",
    "        print(new_article.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb1fb20c-fb38-4f5a-9e34-f401bca2d8cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "記事作成に使用するモデル: openai\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      "タイトル    　　 　:  空飛ぶ自動車\n",
      "記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\n",
      "ファイル名         : test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タイトル: 空飛ぶ自動車\n",
      "\n",
      "最近、未来の乗り物として話題になっている「空飛ぶ自動車」。映画やアニメの中だけに存在する夢の乗り物だと思っていたら、実際に開発が進んでいるんです。日本の吉田コーポレーションが、その空飛ぶ自動車を発表したとのこと。これには、日常的に「空を飛ぶ」という夢を抱いていた私の心が躍りました。\n",
      "\n",
      "吉田コーポレーションの空飛ぶ自動車は、なんと「重力制御装置」を搭載しているそうです。この装置により、従来の航空機とは全く異なる方式で空中を飛ぶことができるというから驚きです。思わず「重力を制御する」って、どういうこと？と首をかしげたくなりますよね。私たちが普段感じる重力を、まるで無視するように浮かぶことができるなんて、夢が膨らみます。\n",
      "\n",
      "価格は2000万円からということなので、一気に手が届きにくくなりますが、今後の普及を考えれば初期投資としては許せる範囲なのかもしれません。でも皆さんはどう思いますか？2000万円という価格、あなたは支払いますか？それとも「夢物語だ」と思いますか？\n",
      "\n",
      "さて、気になるのはこの空飛ぶ自動車の機能です。吉田コーポレーションによれば、オプションで水中移動も可能とのこと。陸上、水中、そして空中の全てを自由に移動できるなんて、本当に未来の乗り物って感じがします。家族でのドライブも、ちょっとした冒険ができそうでワクワクしませんか？\n",
      "\n",
      "実は、私も数年前に、友人と一緒に空港付近の展望デッキで「いつか空飛ぶ車ができたらな〜」と話していたんです。その時は夢みたいな話でしたが、実際にこうやって開発が進んでいると、本当に実現しそうだなと感じます。もしこの空飛ぶ自動車が普及したら、通勤はもちろん、旅行やドライブのスタイルもガラッと変わりそうですよね。\n",
      "\n",
      "最近では、都市部の渋滞が深刻な問題ですが、空飛ぶ自動車が普及すれば、道路が混雑することも少なくなるかもしれません。上下左右の自由な移動が可能になると、旅先の選択肢も広がります。どこにでも自分の行きたいところへ直接行けるなんて、考えただけで楽しくなってきませんか？\n",
      "\n",
      "ただ、空を飛ぶことには安全性も求められます。空中での交通ルールや事故防止のためのシステムなど、まだまだ開発しなければならないことも多そうです。飛行機やヘリコプターの技術をどう取り入れるのか、さまざまな課題が残っていることは確かです。でも、未来のために挑戦する姿勢には心から賛同したいです。\n",
      "\n",
      "空飛ぶ自動車について考えると、さまざまな夢が広がりますね。あなたは空飛ぶ自動車が実現したら、どんなことをしてみたいですか？海の上を飛びながら、友達とバーベキューなんて楽しいですよね。もしくは、空中散歩をしてみたいです。自分の家の上を飛んでみたり、街を見下ろしたりするのも面白そうです。\n",
      "\n",
      "吉田コーポレーションが開発している空飛ぶ自動車、これからますます注目していきたいと思います。実際にこの夢の乗り物が私たちの日常にどのように役立つのか、一緒に見守っていきましょう。あなたの夢の中にも、空飛ぶ自動車が登場しますように！\n",
      "=================================================================================\n",
      "\n",
      "申し訳ありませんが、条件に従った修正が必要です。以下は修正後の記事です。\n",
      "\n",
      "---\n",
      "\n",
      "# タイトル: 空飛ぶ自動車は実現可能か？\n",
      "\n",
      "最近、未来の乗り物として話題になっている「空飛ぶ自動車」。映画やアニメの中でだけに存在する夢の乗り物だと思っていたら、実際に開発が進んでいるんです。日本の吉田コーポレーションが、空飛ぶ自動車を発表したとのこと。この装置には、重力制御装置を搭載しているそうです。改めて、「重力を制御する」とはどういうことか？ということに首をかしげてしまいますよね。\n",
      "\n",
      "私も数年前に、友人と一緒に空港付近の展望デッキで「いつか空飛ぶ車ができたらな〜」なんて話していたんです。その時は夢みたいな話でしたが、吉田コーポレーションのニュースを聞いてからは、心が躍りました。\n",
      "\n",
      "この空飛ぶ自動車の価格は、なんと2000万円から。価格だけを聞くと「手が届かない」と感じてしまいますが、一気に手に入れるのではなく、夢を追いかける過程も楽しむことが大切かもしれませんね。\n",
      "\n",
      "また、オプションで水中移動も可能との報告があります。陸上、空中、水中の全てを自由に移動できるなんて、本当に近未来的です。これが実現すれば、旅行やドライブのスタイルも大きく変わることでしょう。\n",
      "\n",
      "あなたは、この「空飛ぶ自動車」をどのように利用したいと思いますか？自由に空を飛び回ったり、海の上を滑ったりしたいという夢が、すぐに現実になるかもしれません。吉田コーポレーションにとって、これは単なるスタートに過ぎませんが、私たちの未来を大きく変える可能性を秘めているのです。\n",
      "\n",
      "また、空飛ぶ自動車が普及することで、現在の渋滞問題が少しでも緩和される可能性もあります。都市部の交通渋滞が深刻化し続ける中、空飛ぶ自動車がその解決の一助になればと期待しています。\n",
      "\n",
      "安全性のためには、充分な規制やシステムも必要ですが、空飛ぶ自動車が普及した暁には、私たちの生活は一変すると考えられます。上下左右の自由な移動が可能になれば、旅先の選択肢も広がり、より豊かな体験ができることでしょう。\n",
      "\n",
      "実際にこの技術がどのように発展していくのか、我々は見守るしかありませんが、もしあなたが空飛ぶ自動車に乗る機会があれば、どんな体験をしてみたいですか？新たな技術が日常生活に登場するのは、いつになるのか、夢が膨らみますね。\n",
      "\n",
      "私たちはみな、未来のロマンを抱きつつ、技術の進化を楽しみにしています。どれだけの夢の乗り物が、私たちの日常生活に入ってくるのか、ワクワクが止まりません。これからも吉田コーポレーションの活動に注目していきたいと思います。\n",
      "\n",
      "---\n",
      "\n",
      "この修正によって、条件を満たした内容となっています。ご確認ください。\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "記事生成に使用するモデルを選択してください (openai, google または ollama) \n",
      " openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "記事作成に使用するモデル: openai\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "記事のタイトルを入力してください\n",
      "[\"esc\"を入力して終了]\n",
      "============================================\n",
      "タイトル    　　 　:  スペースXの「スターリンク」衛星、火の玉になって落下–毎日4〜5機が大気圏に再突入\n",
      "記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\n",
      "ファイル名         : test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タイトル: スペースXの「スターリンク」衛星、火の玉になって落下–毎日4〜5機が大気圏に再突入です\n",
      "\n",
      "最近、アメリカの空でちょっとした火球が目撃されたことを知っていますか？それは、SpaceX社が運営する「Starlink」衛星が大気圏に再突入した際に見られた現象なんです。私はこのニュースを聞いたとき、なんとも不思議な気持ちになりました。この火の玉、みなさんは実際に見たことありますか？それとも、どんな感じだったと思いますか？\n",
      "\n",
      "この火球は、ウィスコンシン州、ミシガン州、イリノイ州などアメリカ中西部で目撃されたそうです。SNSでは、見事な瞬間を捉えた動画や写真がたくさん投稿されて、みんなの話題をさらっていました。見るからに派手で、見逃せない光景だったことでしょう。\n",
      "\n",
      "スターリンク衛星の「Starlink 5693」は、2024年12月から軌道を降下していたとのこと。それにしても、この衛星が約5年の運用を経て、大気圏で燃え尽きるように設計されているという事実は、なんだかロマンティックですよね。宇宙の技術が進化する中、衛星が星となり、夜空に消えていく様子を想像すると、ちょっとした感慨を覚えます。\n",
      "\n",
      "さて、毎日4〜5機のスターリンク衛星が再突入していますが、これって意外と知られていない事実かもしれません。私も以前、夜空を見上げて流れ星を探そうとした時に、ふとこの衛星が落下していく様子を考えてみました。まあ、流れ星だと思って見上げたら、実はそれがスターリンクだったなんてこともあるかもしれませんね。\n",
      "\n",
      "こういう話をしていると、昔のことを思い出します。大学時代、友達と一緒にキャンプに行ったとき、夜空の下で流れ星を見たことがあるんです。その時、誰かが「願い事を思い浮かべて！」と言い出して、みんなで一斉に宇宙にお願いを送りました。願い事はそれぞれ違ったけれど、あの瞬間の空の美しさと、みんなで共通の体験をしている感覚がとっても楽しかったなあ。\n",
      "\n",
      "ただ、このスターリンクの火球現象は美しいだけではなく、実際に日々宇宙のごみ問題という課題も抱えているんです。再突入する際には、落下地点に影響を与える可能性も考慮しなければなりません。さすがに轟音を立てて落下したりしたら大変ですから、これからも注意が必要ですね。\n",
      "\n",
      "このように、テクノロジーの進化が新たな風景を生み出し、同時にさまざまな課題を引き起こしているというのは、ちょっと哲学的な話でもあります。皆さんが見た火球はどんな色をしていましたか？また、あの美しい光を見ることができる日は訪れるのでしょうか？\n",
      "\n",
      "今回のスターリンク衛星の火の玉が、ただの燃え尽きる運命を持った衛星であることを忘れずに、我々もこの変化の時代を楽しんでいきたいものですね。次に夜空を見上げたときには、もしかしたら新たなスターリンクの火球を目撃できるかもしれませんよ。あなたは流れ星に願いをかける派、それとも見つけた瞬間に歓声を上げる派ですか？\n",
      "=================================================================================\n",
      "\n",
      "以下に示すのは、記事の修正後の内容です。条件に従い、文体を整え、正しい日本語で記述し、読者への問いかけや体験談も含めています。また、1500文字程度の長さにも適応しています。\n",
      "\n",
      "---\n",
      "\n",
      "**タイトル: スペースXの「スターリンク」衛星、火の玉になって落下**\n",
      "\n",
      "米SpaceX社の衛星インターネット「スターリンク」の一機が、先日、大気圏に再突入し大きな火球として米国中西部で目撃されました。この現象は、ウィスコンシン州、ミシガン州、イリノイ州などで観測され、SNS上でも多くの動画や写真が投稿されています。\n",
      "\n",
      "この衛星は「Starlink 5693」と呼ばれており、2024年12月から徐々に軌道を降下していたと専門家が説明しています。Starlink衛星の設計では、通常5年の運用後に大気圏で燃え尽きるようになっていますが、毎日4〜5機の衛星が世界中で再突入しています。この現象について、皆さんは知っていましたか？\n",
      "\n",
      "私もSNSで流れてきたニュースを見て驚きました。まさに映画のような光景だと思います。特に、この衛星がもたらした火球について、ι私の友人がウィスコンシン州で暗闇の中に浮かぶ大火球を見たそうです。彼によれば、それはまるで流れ星のような美しい現象だったとのことです。\n",
      "\n",
      "SNSでは多くの目撃者が自らの体験を共有しており、「あの瞬間に立ち会えて本当に幸せだった」「夜空が明るく照らされた」というコメントがたくさん見受けられます。この火球を見ることができた方々の感動は、言葉で表現するには難しいかもしれません。\n",
      "\n",
      "しかし、この衛星が再突入することは一般的な現象であり、火球が目撃されたことに対して意外性は少ないのかもしれません。ただし、こうした現象が起こると、私たちの生活や空の美しさに新たな意味が加わりますよね。\n",
      "\n",
      "さて、Starlink衛星の再突入については、今後も注意が必要です。再突入地点に対して影響を与える可能性があるため、何かの際には適切な対策を考えることが重要です。私たちの大気圏には、地球外からのさまざまな物体が続々と落下していますが、その中にはスペースXの衛星も含まれています。\n",
      "\n",
      "最近、街の空を見上げると、流れ星ばかりではない、さまざまな宇宙の技術が進化していることを実感させられます。皆さんも、こうした火球を見たことがありますか？それとも、空を見上げたときに、流れ星のような一瞬の美しさを感じたことがありますか？そのような瞬間には、思わず願い事をすることでしょう。\n",
      "\n",
      "実際に流れ星を見たことがある方は、その際、どんな願い事をしたか教えてくれると嬉しいです。皆さんがどのような経験をお持ちなのか、ぜひお聞かせください。\n",
      "\n",
      "今回の衛星の火球がもたらした現象は、私たちにとって何か特別な意味を持つのではないかと思います。このような出来事を通じて、宇宙の神秘やその影響を改めて考えるきっかけになれば幸いです。技術の進化が私たちの生活にどのように影響を及ぼしているのかを、皆さんと一緒に考え、共有できることを楽しみにしています。\n",
      "\n",
      "これからも様々な宇宙関連のニュースに注目していきたいですね。次に空を見上げた際には、新たな流れ星や火球に願いを込めてみてはいかがでしょうか。\n",
      "\n",
      "---\n",
      "\n",
      "この修正内容は、条件に沿ったものと考えられます。文章はフランクすぎず、問いかけも含まれています。また、体験談を交えながら読者に親しみやすくしています。文字数も1500字程度となっています。\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 194\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m#----------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 194\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[74], line 137\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# wrighterの作成\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m記事生成に使用するモデルを選択してください (openai, google または ollama) \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m         wrighter \u001b[38;5;241m=\u001b[39m GetLlm(mode)\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m wrighter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2024.10-1/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama   #conda に対応していないため見送り\n",
    "from langchain_community.chat_models import ChatOllama #上記の代わり\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "\n",
    "#==========================================================================================================\n",
    "def GetLlm(mode):\n",
    "    # Chatモデルのインスタンスをストリーミングモードで初期化\n",
    "    if mode.lower() == \"openai\":\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "    elif mode.lower() == \"google\" or mode is None:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7, streaming=True)\n",
    "    elif mode.lower() == \"ollama\":\n",
    "        llm = ChatOllama(model = \"llama3\",streaming=True)\n",
    "    else:\n",
    "        llm = None\n",
    "    return llm\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "def MakeWrighterPrompt(title, fname=None):\n",
    "    if fname is None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブライターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"6. タイトル名はタイトル: タイトル名の形式で出力すること\"\n",
    "            )\n",
    "        # プロンプトテンプレートの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事のタイトルは{title}です。\"\n",
    "            )\n",
    "\n",
    "        # 入力メッセージの作成\n",
    "        prompt = temp.invoke({\"title\": title})\n",
    "\n",
    "    # 参考記事なしの場合\n",
    "    if fname is not None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブライターです。1500文字程度で次のタイトルに沿った記事を作成してください。\"\n",
    "            \"1. 記事が適度にフランクな文体で作成されていること\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. Markdownの形式で記述されていないこと\"\n",
    "            \"5. 記事が日本語で記述されていること\"\n",
    "            \"6. タイトル名はタイトル: タイトル名の形式で出力すること\"\n",
    "            )\n",
    "        # プロンプトテンプレートの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事のタイトルは{title}です。\"\n",
    "            \"取材内容は次のとおりです{data}\"\n",
    "            )\n",
    "     \n",
    "        # 記事作成の材料の読み込み    \n",
    "        loader = TextLoader(fname)\n",
    "        data   = loader.load()\n",
    "\n",
    "        # 入力メッセージの作成\n",
    "        prompt = temp.invoke({\"title\": title, \"data\": data[0].page_content})\n",
    "\n",
    "    # ヒューマンメッセージの作成\n",
    "    human_message = HumanMessage(content=prompt.to_string())\n",
    "    \n",
    "    return (system_message, human_message)\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "def MakeEditorPrompt(article, fname=None):\n",
    "\n",
    "    if fname is None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブメディアの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "            \"1. 記事の文体がフランクすぎないこと\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. 記事がMarkdownの形式で記述しないこと\"\n",
    "            \"5. 記事が正確な日本語で記述されていること\"\n",
    "            \"6. 記事の文字数が1500文字程度であること\"\n",
    "            \"7. タイトルを変更しないでください\"\n",
    "            \"8. タイトル名はタイトル: タイトル名の形式で出力すること\"\n",
    "            \"上記の全条件が守られている文章に修正して下さい。\"\n",
    "            )\n",
    "        # プロンプトの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事本文:{article}\"\n",
    "        )\n",
    "        \n",
    "        prompt = temp.format(article=article)\n",
    "\n",
    "    if fname is not None:\n",
    "        # システムメッセージの作成\n",
    "        system_message = SystemMessage(content=\n",
    "            \"あなたはウェブメディアの編集者です。次の条件が正しく守られているかを判断してください。\"\n",
    "            \"1. 記事の文体がフランクすぎないこと\"\n",
    "            \"2. 記事中に読者への問いかけが含まれていること\"\n",
    "            \"3. 記事が身近な話題の場合、体験談が含まれていること\"\n",
    "            \"4. 記事がMarkdown形式で記述しないこと\"\n",
    "            \"5. 記事が正確な日本語で記述されていること\"\n",
    "            \"6. 記事の文字数が1500文字程度であること\"\n",
    "            \"7. タイトルを変更しないでください\"\n",
    "            \"9. タイトル名はタイトル: タイトル名の形式で出力すること\"\n",
    "            \"8. 記事が材料に沿って作られていること\"\n",
    "            \"上記の全条件が守られている記事に修正して下さい。\"\n",
    "            )\n",
    "        # 記事作成の材料の読み込み\n",
    "        loader = TextLoader(fname)\n",
    "        data = loader.load()\n",
    "\n",
    "                                       \n",
    "        # プロンプトの作成\n",
    "        temp = PromptTemplate.from_template(\n",
    "            \"記事の材料:{materi}\"\n",
    "            \"記事本文:{article}\"\n",
    "            )\n",
    "    \n",
    "        prompt = temp.format(materi=data, article=article)\n",
    "    # ヒューマンメッセージの作成\n",
    "    human_message = HumanMessage(content=prompt)\n",
    "    \n",
    "    return (system_message, human_message)\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "def main():    \n",
    "    while True:\n",
    "        # wrighterの作成\n",
    "        while True:\n",
    "            mode = input(\"記事生成に使用するモデルを選択してください (openai, google または ollama) \\n\")\n",
    "            wrighter = GetLlm(mode)\n",
    "            if wrighter is not None:\n",
    "                break\n",
    "            \n",
    "            print(\"対応しているモデル名を入力してください\")\n",
    "    \n",
    "        print(\"記事作成に使用するモデル:\" , mode)\n",
    "\n",
    "        # 入力テキストの作成と記事生成\n",
    "        # ユーザーから記事タイトルの入力\n",
    "        title = input(\"============================================\\n\"\n",
    "                      \"記事のタイトルを入力してください\\n[\\\"esc\\\"を入力して終了]\\n\"\n",
    "                      \"============================================\\n\"\n",
    "                      \"タイトル    　　 　: \"\n",
    "                     )\n",
    "        \n",
    "        if title.lower() == \"esc\":\n",
    "            print(\"終了します。\")\n",
    "            break\n",
    "        \n",
    "        # 情報の追加\n",
    "        while True:\n",
    "            materi = input(\"記事作成に使用するファイルを入力してください。使用しない場合はNoneを入力してください\\n\"\n",
    "                           \"ファイル名         :\"\n",
    "                          )\n",
    "            \n",
    "            if materi == \"None\":\n",
    "                materi = None\n",
    "                break\n",
    "            if os.path.isfile(materi):\n",
    "                break\n",
    "\n",
    "            print(\"[Error]ファイル\"+materi+\"が見つかりません。\")\n",
    "\n",
    "        # wrighterに入力するテキストを作成\n",
    "        system_message, human_message = MakeWrighterPrompt(title, fname=materi)\n",
    "        \n",
    "        # raw_articleを作成\n",
    "        article = []\n",
    "        for chunk in wrighter.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "                article.append(chunk) # wrighterの出力結果をeditorに渡す\n",
    "        editor = wrighter\n",
    "        print(\"\\n=================================================================================\\n\")\n",
    "        # 編集者によって記事がプロンプトを守っているか確認\n",
    "        # editorに入力するテキストを作成\n",
    "        system_message, human_message = MakeEditorPrompt(article, fname=materi)\n",
    "        # editorによる修正記事の出力\n",
    "        for chunk in editor.stream([system_message, human_message]):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168c69d-d6d0-4ce8-a3ce-709454db6275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
